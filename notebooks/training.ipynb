{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the internet on my laptop works jeesh the webs...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I paid $130 for this game. I got all the colle...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I bought this mic back in March 2015. I've bee...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more work to doooooo HAHA yeah, im happy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@gerard_k no sorry. long day today and tomorro...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  the internet on my laptop works jeesh the webs...        1.0\n",
       "1  I paid $130 for this game. I got all the colle...       -1.0\n",
       "2  I bought this mic back in March 2015. I've bee...       -1.0\n",
       "3          more work to doooooo HAHA yeah, im happy         1.0\n",
       "4  @gerard_k no sorry. long day today and tomorro...       -1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/sentiment_dataset.csv\", index_col=0)\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    if type(text) == np.float64:\n",
    "        return \"\"\n",
    "    else:\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(\"'\", \"\", text) # to avoid removing contractions in english\n",
    "        text = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "        text = re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub('[()!?]', ' ', text)\n",
    "        text = re.sub('\\[.*?\\]',' ', text)\n",
    "        text = re.sub(\"[^a-z0-9]\",\" \", text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ProcessedText'] = df['Text'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 500\n",
    "EMBEDDING_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['ProcessedText'].values\n",
    "sentiments = df['Sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=MAX_LEN, value=VOCAB_SIZE-1, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../src/models/tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "encoded_sentiments = to_categorical(sentiments, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, encoded_sentiments, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "        Dense(32, activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(3, activation='softmax')  # 3 classes: negative, neutral, positive\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 500, 64)           640000    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 500, 32)           2080      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16000)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 3)                 48003     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 690083 (2.63 MB)\n",
      "Trainable params: 690083 (2.63 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "129109/129109 [==============================] - 1031s 8ms/step - loss: 0.4661 - categorical_accuracy: 0.8075 - val_loss: 0.4603 - val_categorical_accuracy: 0.8106\n",
      "Epoch 2/10\n",
      "129109/129109 [==============================] - 1038s 8ms/step - loss: 0.4577 - categorical_accuracy: 0.8112 - val_loss: 0.4612 - val_categorical_accuracy: 0.8112\n",
      "Epoch 3/10\n",
      "129109/129109 [==============================] - 1037s 8ms/step - loss: 0.4558 - categorical_accuracy: 0.8120 - val_loss: 0.4612 - val_categorical_accuracy: 0.8086\n",
      "Epoch 4/10\n",
      "129109/129109 [==============================] - 1024s 8ms/step - loss: 0.4548 - categorical_accuracy: 0.8126 - val_loss: 0.4613 - val_categorical_accuracy: 0.8107\n",
      "Epoch 5/10\n",
      "129109/129109 [==============================] - 1017s 8ms/step - loss: 0.4547 - categorical_accuracy: 0.8127 - val_loss: 0.4609 - val_categorical_accuracy: 0.8114\n",
      "Epoch 6/10\n",
      "129109/129109 [==============================] - 1033s 8ms/step - loss: 0.4546 - categorical_accuracy: 0.8128 - val_loss: 0.4596 - val_categorical_accuracy: 0.8117\n",
      "Epoch 7/10\n",
      "129109/129109 [==============================] - 1019s 8ms/step - loss: 0.4547 - categorical_accuracy: 0.8128 - val_loss: 0.4658 - val_categorical_accuracy: 0.8082\n",
      "Epoch 8/10\n",
      "129109/129109 [==============================] - 998s 8ms/step - loss: 0.4552 - categorical_accuracy: 0.8125 - val_loss: 0.4603 - val_categorical_accuracy: 0.8112\n",
      "Epoch 9/10\n",
      "129109/129109 [==============================] - 1016s 8ms/step - loss: 0.4555 - categorical_accuracy: 0.8123 - val_loss: 0.4603 - val_categorical_accuracy: 0.8114\n",
      "Epoch 10/10\n",
      "129109/129109 [==============================] - 1029s 8ms/step - loss: 0.4554 - categorical_accuracy: 0.8123 - val_loss: 0.4626 - val_categorical_accuracy: 0.8091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2021f38c150>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26805/26805 [==============================] - 74s 3ms/step - loss: 0.4621 - categorical_accuracy: 0.8095\n",
      "Test Loss: 0.4621, Test Accuracy: 0.8095\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Prateek\\.conda\\envs\\ai\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('../src/models/sentiment_analysis_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
